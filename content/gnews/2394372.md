###  [:house:返回](README.md)
---


## 美智库警告 AI恐造成人类灭绝风险
`3/14/2024 7:46 AM UTC ` [轉載自GNews](https://gnews.org/articles/2394372)

【[[zh:大纪元]]2024年0[[zh:3月14日]]讯】（[[zh:大纪元]]记者吴旻洲编译报导）人工智慧（AI）技术迅速发展，是否威胁人类生存越来越受到关注。[[zh:美国国务院]]委托[[zh:美国]][[zh:智库]]针对二百多位AI[[zh:公司]]高层、[[zh:国安]]人员与专家进行调查，专家们担忧，最先进的AI系统在最坏的情况下，可能“对人类构成灭绝等级的威胁”，警告[[zh:美国政府]]避免灾难的时间已经不多。

[[zh:美国国务院]]委托AI安全风险顾问[[zh:公司]]Gladstone AI进行调查，在1年多的时间，采访了200多名人员，包括AI[[zh:公司]]高层、网路安全研究人员、[[zh:大规模杀伤性武器]]专家，以及[[zh:国家]]安全官员，Gladstone AI于本周发布这份报告。

报告提到，虽然所有AI实验室都在争取10年内建立通用人工智慧（AGI，一种具有类似人类智慧和自学能力的软体），但这项革命性技术，将对[[zh:民主]]治理和全球安全具有深远影响。

报告说，已有越来越多证据，包括在世界顶级AI会议上发表的实证研究和分析显示，超过一定的能力阈值，AI可能会变得不可控。专家们最担心的是，最先进的AI系统可以[[zh:武器]]化，可能会造成无法逆转的损害。

其次，AI实验室内部也担忧说，一旦AI发展某种程度后，开发人员会对他们自己开发的系统“失去控制”，可能会对全球安全造成“毁灭性后果”。

## AGI若失控 恐酿成毁灭性灾难

面对AGI技术快速发展，监管能力却远跟不上开发的速度，实验室高阶主管和工作人员已公开承认存在这些危险，但因为竞争压力的原故，促使实验室仍然以“牺牲安全为代价”，对人工智[[zh:慧能]]力进行投资。

报告警告，这会增加最先进AI系统可能被“窃取”和“[[zh:武器]]化”，并用来对抗[[zh:美国]]的可能性，如[[zh:武器]]化[[zh:机器人]]、[[zh:无人机]]等等，以及[[zh:武器]]化的[[zh:生物]]和材料[[zh:科学]]，存有挑起AI“军备竞赛”、冲突以及“大规模毁灭性[[zh:武器]]规模的致命事故”的风险。

其他灾难还包括，由AI驱动的“大规模”虚假资讯活动，这些活动会破坏社会稳定，并削弱对机构的信任。AGI被视为“失控导致灾难性风险的主要驱动因素”

目前AGI仍处于理论性，目标是建立类似人类智慧和自学能力的软体，而且不需要编程，就能在任务之间学习，并适应新的任务和环境。包括OpenAI、Google DeepMind、Anthropic和Nvidia都曾公开表示， AGI可能会在2028年实现。

## 不能再放任 [[zh:政府]]迫切需要干预

“[[zh:美国政府]]显然迫切需要进行干预”，作者在报告中呼吁，应采取重大新措施来应对这项威胁，包括实施“紧急”监管保障措施、限制可用于训练人工智慧模型的电脑能力。

报告建议，应该禁止对超过一定阈值的高级AI系统进行训练、尽可能缓和所有AI开发人员之间的竞争动态，并降低晶片行业制造更快硬体的速度。一旦尖端模型的安全性证据得到充分证明，AI机构就可以提高门槛。若在现有模型中发现危险功能，[[zh:政府]]则可以降低安全阈值。

不过，该提案可能会面临[[zh:政治]]困难，目前[[zh:美国政府]]的AI政策是设定运算阈值，高于该阈值则适用额外的监控和监管要求，但不会限制并指其违法。[[zh:美国政府]][[zh:智库]][[zh:战略与国际研究中心]]（CSIS）称，[[zh:美国政府]]极不可能采纳这一建议。

## 42%商界人士也忧心忡忡

已有越来越多的专家警告，AI的快速发展可能会威胁到人类的生存。

被业界誉为“AI教父”的辛顿（Geoffrey Hinton）去年[[zh:4月]]辞去了Google的工作，他当时受访时坦言，AI进步速度远超预期，有10%的可能性，会在未来30年内导致人类灭绝。

去年[[zh:6月]]，辛顿与其他数十位人工智慧产业领袖、学者和其他人士共同签署一项声明，呼吁减轻人工智慧灭绝的风险，应该成为“全球优先事项”。

商界领袖虽然已在AI领域投资了数十亿[[zh:美元]]，但也同样为此感到担忧。去年，[[zh:美国]][[zh:耶鲁大学]]执行长[[zh:高峰]]会上接受调查的执行长中，有42％的人表示，人工智慧有可能在5到10年后毁灭人类。

Gladstone AI也采访了包括ChatGPT所有者OpenAI、Google DeepMind、Facebook母[[zh:公司]]Meta和Anthropic的技术和领导团队等人，并警告虽然AI已经是一项[[zh:经济]]变革技术，继续吸引投资者和公众，但也存在真正的危险。

报告提到，一名知名人工智慧实验室员工表示，如果将下一代人工智慧模型以开放获取的方式发布，那将“非常糟糕”，这些模型可能会被用于干预选举、操纵选民等领域，可能会对[[zh:民主]]造成破坏。◇

责任编辑：昌英
