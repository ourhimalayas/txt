###  [:house:返回](README.md)
---


## OpenAI发布新规则：董事会有权阻止发布AI模型
`12/19/2023 1:59 AM UTC ` [轉載自GNews](https://gnews.org/articles/2126434)

PANews [[zh:12月19日]]消息，OpenAI发布名为“准备框架”（Preparedness Framework）的新规则，旨在确保前沿[[zh:人工智能]]模型的安全。根据此规则，OpenAI将对所有前沿模型进行评估并不断更新其“记分卡”。此外，OpenAI还将定义触发基准安全措施的风险阈值，其规定了四个安全风险等级，只有缓解后得分在“中”或以下的模型才能部署；只有缓解后得分在“高”或以下的模型才能进一步开发。另外，OpenAI还将针对高风险或临界（缓解前）风险级别的模型实施额外的安全措施。

值得注意的是，OpenAI表示，“我们正在建立一个跨职能的安全咨询小组，审查所有报告，并将报告同时提交领导层和[[zh:董事会]]。虽然领导层是决策者，但[[zh:董事会]]拥有逆转决策的权利。”目前，该框架还处于初始Beta版本。
