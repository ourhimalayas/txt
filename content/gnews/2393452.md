###  [:house:返回](README.md)
---


## NEAR 如何搭上 AI 的顺风车？
`3/14/2024 3:01 AM UTC ` [轉載自GNews](https://gnews.org/articles/2393452)

最近，NEAR founder @ilblackdragon 将亮相[[zh:英伟达]] AI 大会的消息，让 NEAR 公链赚足了眼球，[[zh:市场]]价格走势也喜人。不少朋友疑惑，NEAR 链不是 All in 在做链抽象麽，怎麽莫名其妙就成了 AI 头部公链了？ 接下来，分享下我的观察，顺带科普下一些 AI 模型训练知识：

1）NEAR 创始人 Illia Polosukhin 有过较长时间的 AI 背景，是 Transformer 架构的共同构建者。而 Transformer 架构是如今 LLMs 大型语言模型训练 ChatGPT 的基础架构，足以证明 NEAR 老板在成立 NEAR 前确实有 AI 大模型系统的创建和领导经验。

2）NRAR 曾在 NEARCON 2023 上推出过 NEAR Tasks，目标是为了进行[[zh:人工智能]]模型的的训练和改进，简单来说，模型训练需求方（Vendor）可以在平台发布任务请求，并上传基础数据素材，用户（Tasker）可以参与进行任务答题，为数据进行文本标注和图像识别等人工操作。任务完成後，平台会给用户 NEAR [[zh:代币]]奖励，而这些经过人工标注的数据会被用於训练相应的 AI 模型。

比如：AI 模型需要提高识别图片中物体的能力，Vendor 可以将大量图片中带有不同物体的原始图片上传到 Tasks 平台，然後用户手动标注图片上上物体位置，就可以生成大量「图片 - 物体位置」的数据，AI 就可以用这些数据来自主学习来提高图片识别能力。

乍一听，NEAR Tasks 不就是想社会化人工工程来为 AI 模型做基础服务嘛，真有那麽重要？ 在此加一点关於 AI 模型的科普知识。

通常情况下，一次完整的 AI 模型训练，包括数据采集、数据预处理和标注、模型设计与训练、模型调优、微调、模型验证测试、模型部署、模型监控与更新等等过程，其中数据标注和预处理为人工部分，而模型训练与优化为机器部分。

显然，大部分人理解中的机器部分要明显大於人工部分，毕竟显得更高科技一些，但实际情况下，人工标注在整个模型训练中至关重要。

人工标注可以为图像中的对象（人、[[zh:地点]]、事物）等添加标签，供计算机提升视觉模型学习；人工标注还能将语音中的内容转化为文本，并标注特定音节、单词短语等帮助计算机进行语音识别模型训练；人工标注还可以给文本添加一些快乐、悲伤、愤怒等情感标签，让[[zh:人工智能]]增强情感分析技能等等。

不难看出，人工标注是机器开展深度学习模型的基础，没有高质量的标注数据，模型就无法高效学习，如果标注数据量不够大，模型性能也会受到限制。

目前，AI 微创领域有很多基於 ChatGPT 大模型进行二次微调或专项训练的垂直方向，本质上都是在 OpenAI 的数据基础上，额外增加新的数据源尤其是人工标注数据来施展模型训练。

比如，医疗[[zh:公司]]想基於医学影像 AI 做模型训练，为医院提供一套在线 AI 问诊服务，只需要将大量的原始医学影像数据上传到 Task 平台，然後让用户去标注并完成任务，就产生了人工标注数据，再将这些数据对 ChatGPT 大模型进行微调和优化，就会让这个通用 AI 工具变成垂直领域的专家。

不过，NEAR 仅仅凭藉 Tasks 平台，就想成为 AI 公链[[zh:龙头]]显然还不够，NEAR 其实还在生态系统中进行 AI Agent 服务，用来自动执行用户一切链上行为和操作，用户只需授权就可以自由在[[zh:市场]]中买卖资产。这有点类似 Intent-centric，用 AI 自动化执行来提升用户链上交互体验。除此之外，NEAR 强大的 DA 能力可以让它在 AI 数据来源的可追溯性上发挥作用，追踪 AI 模型训练数据有效性和真实性。

总之，背靠高性能的链功能，NEAR 做 AI 方向的技术延展和叙事引导，似乎要比纯链抽象要不明觉厉多了。

半个月前我在分析 NRAR 链抽象时，就看到了 NEAR 链性能 + 团队超强 web2 资源整合能力的优势，万万没想到，链抽象还没有普及开来摘到果子，这一波 AI 赋能再一次把想象力放大了。

Note：长期关注还是得看 NEAR 在「链抽象」上的布局和产品推进，AI 会是个不错的加分项和牛市催化剂！ #NEAR

本文获得《NEAR 如何搭上 AI 的顺风车？》授权转载，作者：Haotian
