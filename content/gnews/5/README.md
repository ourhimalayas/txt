###  [:house:返回首頁](https://github.com/ourhimalayas/txt)
---


## “大脑如何学习”的科学认知
` 英國倫敦喜莊園 Himalaya London Club UK` [轉載自GNews](https://gnews.org/zh-hans/1716175/)

分享者：兴国
[![](https://spark.adobe.com/page/fcjl6LIqydDnv/images/d1125a88-641c-4361-8d3b-9f1bb32bf530.png?asset_id=4abf1ec6-2b4f-4d36-84ed-19ce0e63906c&amp;img_etag=%222897c3837501ddd629c7af61595f1e94%22&amp;size=1024)](https://spark.adobe.com/page/fcjl6LIqydDnv/images/d1125a88-641c-4361-8d3b-9f1bb32bf530.png?asset_id=4abf1ec6-2b4f-4d36-84ed-19ce0e63906c&amp;img_etag=%222897c3837501ddd629c7af61595f1e94%22&amp;size=1024)
正值QMAY和正义小新等战友筹备新中国联邦儿童的网课项目，郭先生也宣布由法治基金资助，而这很可能是新中国联邦教育事业的发端。仅以此文献给所有新中国联邦的父母和爱学习的战友们，作为我们对这一历史时刻的一个共同纪念和祝贺。

今天我们跟随旅美物理学家万老师了解一本书：《我们怎样学习：大脑缘何（目前为止）比机器学得快》（How We Learn: Why Brains Learn Better Than Any Machine… for Now），作者，法国心理学和认知科学家，Stanislas Dehaene（斯坦尼拉斯•迪昂，以下简称“迪昂”） 。

天下的父母都知道孩子学习的重要性，但只有很少的父母有关于“学习”和决定学习的“大脑”方面的科学认知。

大脑到底是如何学习的？

迪昂这本书主要是关于学习的底层原理，结合了脑神经科学、认知心理学和计算机科学，就像一个路标，不仅告诉我们有关学习的最新研究进展，更介绍了关于学习的基本原理。了解这些基本原理，我们就可以更灵活地运用它们，事半功倍，更有效地学习，尤其是更有效地帮助和指引孩子。

大脑可以看作一台神奇的学习机器，涉及一个词：Brain Plasticity（大脑的可塑性），指大脑远比我们知道的更神奇并可以操作。

书中有一些脑科学家收集并观察的案例：一个三岁小孩头部中弹，导致全身瘫痪并且彻底失明，但他的语言天赋却完全不受影响，到七岁时，他居然会说几种语言，还为自己的小说配图插画并出版！他甚至能想象出并画出一些无法看见的事物。

迪昂还列举下面这样类似的案例。一个孩子十一岁那年双目失明，长大后居然成了知名数学家，难以置信的是他的研究对象是代数几何：他如何看到并做几何题呢？一个被切除了大脑整个左半球的孩子可以创作出非常高水准的绘画。一群从小被扔进孤儿院与世隔绝的孩子，长大之后也和正常人一样生活工作……那么家长还有什么可担心的？

可另一方面，有时候大脑因为一个小小的损伤，就会失去重要的学习功能。有人在受伤后发现自己不会阅读了，对眼前的文字怎么都不认识，然后不管多么努力地训练，阅读速度都比不上一个幼儿园小孩。

这本书的主题就是怎样才能把大脑用好。

庆幸的是我们人类的大脑都相差不大，知识的基本原理也一样，这本书中的知识适用于每一个人。

只是迪昂的这本书强调一个最关键的原理：有些知识是天生的。

爱德华·威尔逊《创造的起源》里介绍过“先备学习（prepared learning）”这个概念。科学家的最新认识是大脑不是白板，小孩刚出生，就已经预装了很多知识。对光线和声音如何反应，如何关注语言，天生害怕危险的东西，这些都不用专门学，都已经写在基因里了，几乎每个孩子都天生就会。

但并不是所有知识都预装了，否则就不需要“学习”和“教育”了。

因为，首先是装不下，人类 DNA的全部信息、包括把各种冗余都算上，只有750M，相当于一张老式 CD 的容量。更重要的是，把大部分知识留到出生以后学习是更好的策略，因为没人能事先保证何时能用上哪些知识。

戴维·威尔逊《生命视角》里讲到先天：基因和传承到的文化，以及后天：学习新东西，这个策略能让我们最灵活地适应新环境。

所有生命几乎都有学习能力，包括最简单的线虫：它能适应环境变化，能记住各种线索去找到营养丰富的地方，并且在路上避开有它不喜欢的气味的地点。

人类尤其擅长学习。相对于需要学习的知识而言，我们大脑的“容量”几乎是无限的。

与其他生命相比，人类似乎有最大的学习潜能，学习对我们的影响也最大，不同的人因为学习而产生的差距也最大。能在青少年时期用十几年的时间专门受教育，这是现代人的特权。这种系统性的教育让人的短期记忆力比从来没有受过教育的人高出一倍。每多受一年教育，平均智商就能提高几分。学习不但是人类不断适应新环境的关键手段，而且能把人变成很不同的人。

对此，我们可以自行脑补一下，电影中童年差别不大的两个小伙伴，一人因为后天机缘有条件不断深造，接触新知识，看到新事物；一人只能先工作养家（并且没有机会自我深造，开阔视野），知识会在两人的见识、思考能力、气质等许多方面形成巨大的鸿沟。

但不论怎样，我们终究也是一种生物。先天预装知识和后天学习相配合这个机制，对我们非常重要。

这本书中有个非常有趣的逻辑：可称为“反向仿生学”。

上世纪八十年代，计算机科学家有感于传统算法做人工智能踟蹰难进，转向人脑学习，这样就有了神经网络算法 ，现在也叫“机器学习”，是一切 AI（人工智能）的基础。计算机科学家在这个基础上发明了各种策略和方法，其中也是不断地借鉴人脑机制，他们非常关注脑科学的进展。可以说 AI 是对大脑的仿生学。

可谓“教学相长”，脑科学家也很关心 AI 算法的进展，并从 AI 中悟出很多道理。有时候计算机科学家独立发明一个能提高机器学习效率的新方法，脑科学家就会发现好像人脑也是这样的……这就是反向仿生学。

大脑也是一个神经网络。有时候和一个跟自己相似的东西对照，更有助于看清自己。大脑的一些基本学习原理与AI相同，高级的原理会比 AI 高得多，今天我们先说相同点。

1.学习模型

迪昂说，学习本质上就是训练人类大脑内部的模型。

模型是真实世界在头脑里的一个缩影，不可能完全再现真实世界，但应该包含真实世界的关键特征，能用于描述，甚至预测真实世界。

大脑和 AI 都是神经元的网络，其模型都是神经元的连接结构和连接强度，可以用一系列参数表示。学习就是训练模型，就是通过和真实世界互动，用数据的反馈来调整那些参数。

2.学习分层

神经网络模型是分层的。比如学语言，不管是小孩学说话还是 AI 中的语音识别，最底层都是识别音节，是简单的声音。往上一层是字词，再往上是语法，先连成简单句子，再往上一层是意思……每一层有每一层的规律。在机器学习领域，分层是一个重大进步，分层的神经网络就叫“深度学习”网络。

3.监督学习

怎么训练模型的参数呢？最简单的方法就是随时提供有效的反馈。

在机器学习领域，这叫做“有监督式学习（Supervised Learning）”。神经网络每做一个动作都会收到好的反馈：既知道差距多少也知道差距的方向，然后下一步明确知道该怎样对参数进行微调。当然有些学习简单，比如打球下棋，因为只有几个参数，复杂的学习需要调整的参数非常多，要有极多的训练数据，但是原理相同。

反馈，是学习的关键。做题后知道结果，考试后知道成绩都是反馈。日常生活中，父母对孩子问题的答复，也是一种监督学习，哪怕告诉孩子自己不会，建议并鼓励孩子自己通过某种方式找到答案，都是很好的反馈。

4.“任意的震动”

机器学习中，有时候通过一系列反馈能很快找到一个最优解，但是难以确定它是全局的最优解，因为只搜索了一个局部。计算机科学家的办法是故意给学习加入一些随机的变化，就好像生物演化中的基因突变一样，也许就能收获惊喜。

有时混乱能带来惊喜。同样，只要不会对孩子造成大的伤害，给孩子一些尝试新事物，给孩子“搞砸”“捣乱”的自由和机会， 同样很可能会有惊喜。

5.无监督学习

有老师手把手地教，每一步都给反馈当然好，如果没有老师怎么办？也许更好。当初 DeepMind公司出的阿尔法狗（ AlphaGo），并不是跟围棋教练学的下棋，它们使用的是“无监督学习（unsupervised learning）”算法。

无监督学习只有一个外部反馈，那就是最终这盘棋是赢是输的结果。过程中间哪一步走的对不对，没有人告诉。

无监督学习算法会分出两个角色，一个是批评者（critic），一个是行动者（actor）。批评者的任务是根据以往的对局经验，随时评估当前局面的胜率大小。比如你的地盘很大，它就能感觉到你取胜的概率大。行动者则是根据批评者的评估意见试探下一步走法：如果批评者说走这里胜率会降低，行动者就需要换个地方……

对应到孩子，就是对作业或考试自我对照答案，孩子们会根据结果自我发现问题，自我调整，也是自学的有效方法。

人类大脑就是这样学习的。

6.抓住关键点

机器学习的模型是不是参数越多越好呢？不是。参数太多会让人陷入“过度拟合” （拟合过度精确可能造成反向结果）：比如数学课，学解题的套路是一般性，而不是那些例题里特殊的细节。要善于学习，也要善于忽略，才能抓住关键点。

7.内隐知识

机器学习中的“卷积算法” （对事物的识别通过多个逻辑层逐级按特定要求识别），可以就把计算机图形识别的能力提高到实用水平。这种算法的关键是它并不是在空白状态下识别图：它已经对相关的图形都有了一定的了解，能够识别一些最基本的图案，比如线条、圆圈、斑点等等。新的图形在它眼中都是已知图案的组合。它善于运用自己的“内隐知识”。

大脑的学习也是如此。我们不是“从零开始”学，而是把新知识看做旧知识的组合。我们出生之前，基因就已经告诉我们如何识别声音和光线，所以接下来的语音和人脸识别都是在更高的层面上进行的，所以宝宝才学的那么快那么自然。

透过机器学习，我们也能了解自己的学习。我们的基础知识是否扎实？我们把失败当做反馈？还是把反馈当做失败？我们做事的时候内心有“批评者”吗？批评者会影响我们的情绪吗？我们喜欢新事物吗？……这样对比下来，大多数人的学习态度都无法胜出没有情绪干扰的机器。

但大脑的确远比机器强大得多。如果您有兴趣，我们继续进一步了解这本书。

*参考资料：*

*1. 万维钢翻译解读《我们如何学习》*

*2. Stanislas Dehaene《How We Learn: Why Brains Learn Better Than Any Machine… for Now》*

*3.. 爱德华·威尔逊《创造的起源》*

*4.《This View of Life》 David Sloan Wilson.*

*5. Krizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffrey E. 《ImageNet classification with deep convolutional neural networks》*

编辑：【英国伦敦喜庄园编辑部】

校对：仙女儿-文善 | 审核：神奇四侠 | Page：青山

- [点击阅读英国伦敦喜庄园在G-News 的更多精彩文章](https://gnews.org/zh-hans/author/himalaya_hawk/)
- [点击观看英国伦敦喜庄园在G-TV的精彩视频](https://gtv.org/web/#/UserInfo/5ee680a45bd6f123dd104807)
- [欢迎加入【英国伦敦喜庄园】Discord官方群](https://discord.gg/VsNaHaMUsy)

[![](https://spark.adobe.com/page/fcjl6LIqydDnv/images/b7c25957-8b67-4267-b18c-f25d93f5e760.jpg?asset_id=a48ccfb5-5064-4f46-9a66-a67492000fdd&amp;img_etag=%22fb035768c8cb9d7a5024d2e8b5ca4124%22&amp;size=1024)](https://spark.adobe.com/page/fcjl6LIqydDnv/images/b7c25957-8b67-4267-b18c-f25d93f5e760.jpg?asset_id=a48ccfb5-5064-4f46-9a66-a67492000fdd&amp;img_etag=%22fb035768c8cb9d7a5024d2e8b5ca4124%22&amp;size=1024)


 

免责声明：本文内容仅代表作者个人观点，平台不承担任何法律风险。

- [ROL Foundation](https://rolfoundation.org/)
- [ROL Society](https://rolsociety.org/)
- [Terms of use](https://gnews.org/terms-of-use-3/)
- [Privacy Policy](https://gnews.org/privacy-policy/)
