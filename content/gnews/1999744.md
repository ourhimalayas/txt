###  [:house:返回](README.md)
---


## AI与核武器：旧金山拜习会引发的全球关切与挑战
`11/21/2023 11:17 AM UTC 文斌的频道` [轉載自GNews](https://gnews.org/articles/1999744)



刚刚过去的[[zh:旧金山]]拜习会中有有一项内容引起人们关注，就是双方表示不支持[[zh:人工智能]]（AI）应用于[[zh:核武器]]领域，这是为什么呢？

众所周知，AI技术在当今社会中得到了广泛的应用，尤其是在军事领域。军方可以通过引入AI，提高作战效率，减少[[zh:战争]]中的人员伤亡，例如在[[zh:以色列]]清剿哈马斯地道的过程中，AI的应用就带来了非常好的效果。然而，尽管技术的发展为我们带来了许多便利，但在[[zh:核武器]]领域引入AI可能会带来一系列潜在的风险和危机。

![](ipfs://QmepGzeMJrSnBzMyJ3ohubg9vHBXX3c1V7j6huqTmE7N4W?.png)

首先，AI在[[zh:核武器]]系统中的使用可能会引发“无人化”的决策过程，剥夺了人类的道义判断和伦理思考。

与人类相比，AI缺乏道德和伦理的观念，这意味着在关键时刻，它可能会忽略生命的可贵性，仅仅依赖程序和算法来做出决策。这种缺乏人性化的决策过程可能导致灾难性的后果，因为AI不会理解生命的价值和社会的复杂性。

以[[zh:阿富汗战争]]为例，曾经有一位[[zh:无人机]]操作手看到AI传回的画面，显示一个敌方[[zh:武器]]持续攻击己方，但他发现[[zh:武器]]后面是一个房子，里面住满了小孩。面临决策时，他没有按下攻击按钮，因为他考虑到后面有无辜的生命。然而，如果那时[[zh:无人机]]由AI控制，后果可能不堪设想，因为AI会根据预设情境去完全消除威胁，而不会去甄别背后的生命情况。

其次，考虑到目前全球的[[zh:政治]]和[[zh:地缘政治]]紧张局势，将AI引入[[zh:核武器]]系统可能会加剧战略的不稳定性。[[zh:国家]]之间的紧张关系和误判可能导致[[zh:核战争]]的爆发，而AI在这样的情况下可能无法适应复杂的[[zh:政治]]和战略考量，进而做出过于激进的决策。这将使国际社会陷入危险的境地，带来难以挽回的后果。

另外，AI系统的漏洞和被攻击的风险也是不可忽视的因素。

AI系统的漏洞曾经差一点酿成大祸，那还是在1980年，有一次[[zh:苏联]]的AI探测到一个辐射云的光彩信息，误判为[[zh:美国]]的核攻击前兆，就做出了发射[[zh:核武器]]的命令。幸运的是，当时一位名叫斯坦尼斯拉夫的[[zh:前苏联]]军官在最后时刻做出了人类的决定，避免了可能的核战。

而在当今[[zh:网络攻击]]频繁的环境下，[[zh:核武器]]系统的AI可能成为恶意攻击的目标。黑客可能利用漏洞干扰或篡改AI算法，使[[zh:核武器]]系统做出错误的判断，从而引发不必要的冲突。

![](ipfs://Qmf1pJHaKWuYJnT2Wd9F9ptMyiE2x93Uv8axabrjBVYkKu?.png)

最后，考虑到[[zh:核武器]]的巨大杀伤力和毁灭性，任何技术引入都必须经过极为慎重的考虑。AI虽然在许多领域取得了显著的成就，但在[[zh:核武器]]领域的错误决策可能导致灾难性的后果，对全人类产生不可逆转的影响。

在当今局势下，考虑到各个拥有[[zh:核武器]]的[[zh:国家]]，如[[zh:中国]]、[[zh:俄罗斯]]和北韩，这些[[zh:国家]]的[[zh:核武库]]数量在增加，如果AI被用于[[zh:核武器]]系统，将会带来更大的风险，因此，拜习会的观点是明智的。

但是我们必须明白，[[zh:中共]]的搞垮、搞弱、搞死[[zh:美国]]的3F计划始终没有改变，如果AI应用于核武领域将有助于3F计划的实施，他们一定会偷偷的钻营，[[zh:中共]]向来不遵守任何协议和规则，对此，我们呼吁美方给予高度重视。
